# Task ID: 4
# Title: Implement LLM interaction module
# Status: done
# Dependencies: 1
# Priority: high
# Description: Create a module to handle LLM API calls with retry logic and structured JSON response parsing.
# Details:
Implement an LLM client (src/llm_client.py) that sends prompts requesting structured JSON responses with spam_score and importance_score. Add configurable retry logic for failed API calls. Parse JSON responses and handle malformed responses gracefully. Use the temperature setting from the configuration. Include detailed logging of API interactions for debugging. MUST use settings.get_openrouter_api_url() and settings.get_openrouter_api_key() from settings.py facade. API contract: POST to URL from settings, Bearer token auth, JSON response with {"spam_score": <int>, "importance_score": <int>}.

# Test Strategy:
Test successful API calls and response parsing. Verify retry logic works with simulated failures. Test handling of malformed JSON responses. Verify temperature setting is correctly applied.

# Subtasks:
## 1. Create basic LLM client structure [done]
### Dependencies: None
### Description: Set up the foundation for the LLM client module with settings facade and basic API call functionality
### Details:
Create a new module src/llm_client.py with a class that handles LLM interactions. Implement configuration loading using the settings.py facade to read API keys (settings.get_openrouter_api_key()), endpoints (settings.get_openrouter_api_url()), and default parameters (including temperature). Define the basic structure for making API calls to the LLM service with proper error handling. Include a method signature for sending prompts that will later be enhanced with retry logic and response parsing. Ensure all configuration access is through the settings facade, not directly from YAML.

## 2. Implement prompt formatting for structured JSON responses [done]
### Dependencies: 4.1
### Description: Create functionality to format prompts that specifically request structured JSON responses with required fields
### Details:
Develop a prompt formatter that appends instructions to user prompts requesting structured JSON responses. Ensure the formatter explicitly requests spam_score and importance_score fields in the response. Include validation to ensure the prompt maintains the correct format regardless of user input. Create unit tests to verify the formatter correctly structures prompts for JSON responses. The API contract must follow the PDD specification: POST to URL from settings, Bearer token auth, JSON response with {"spam_score": <int>, "importance_score": <int>}.

## 3. Add configurable retry logic for API calls [done]
### Dependencies: 4.1
### Description: Implement robust retry mechanism for handling transient failures in LLM API calls
### Details:
Enhance the basic API call functionality with configurable retry logic. Implement exponential backoff strategy with jitter. Make retry attempts (settings.get_openrouter_retry_attempts(), default 3), delays (settings.get_openrouter_retry_delay_seconds(), default 5), and conditions configurable through the settings facade. Handle different types of failures appropriately (network errors, rate limiting, server errors). Add detailed logging for each retry attempt including reason for failure and backoff time.

## 4. Implement JSON response parsing and validation [done]
### Dependencies: 4.1, 4.2
### Description: Create functionality to parse, validate and safely extract data from LLM JSON responses
### Details:
Develop a response parser that extracts and validates JSON from LLM responses. Implement schema validation to ensure responses contain required fields (spam_score and importance_score). Handle malformed JSON gracefully with appropriate error messages and fallback values. Create a structured response object that standardizes access to parsed data. Add unit tests with various response scenarios including valid, malformed, and missing field cases. Ensure the parser follows the API contract specified in the PDD.

## 5. Implement comprehensive logging system [done]
### Dependencies: 4.1, 4.3, 4.4
### Description: Add detailed logging throughout the LLM interaction process for monitoring and debugging
### Details:
Implement a comprehensive logging system that captures all aspects of LLM interactions. Log prompt details (with sensitive information redacted), API call parameters including temperature setting, response data, parsing results, and any errors encountered. Add timing information for performance monitoring. Create different log levels for normal operation vs. debugging. Ensure logs are structured in a way that facilitates analysis and troubleshooting. Integrate the logging with the application's main logging system. Use the settings facade to access log file paths and other logging configuration.

