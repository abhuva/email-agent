{
  "tasks": [
    {
      "id": 1,
      "title": "Set up project configuration structure",
      "description": "Create a well-structured YAML configuration system that organizes all user-configurable parameters into logical groups according to the PDD.",
      "status": "done",
      "dependencies": [],
      "priority": "high",
      "details": "Implement a config.yaml file with sections for `imap:`, `paths:`, `openrouter:`, `processing:`, etc. Include parameters for credentials, paths, thresholds, IMAP flags, and LLM parameters (including temperature). Add comprehensive comments for each setting. Create a configuration loader module that validates required fields and provides sensible defaults where appropriate. Implement a settings.py facade that provides getter methods for all configuration values, ensuring all modules access configuration through this facade rather than directly from YAML. Ensure credentials are loaded from environment variables for security.",
      "testStrategy": "Verify that the configuration loads correctly with valid YAML, handles missing optional values with defaults, and raises appropriate errors for missing required values. Test that the settings.py facade correctly provides access to all configuration values.",
      "subtasks": [
        {
          "id": 1,
          "title": "Define YAML configuration structure and sections",
          "description": "Create the basic structure of the config.yaml file with all required sections and placeholder values as specified in the PDD",
          "status": "done",
          "dependencies": [],
          "details": "Create a config.yaml file with the following sections as specified in the PDD: `imap:`, `paths:`, `openrouter:`, `processing:`. Include placeholder values and comprehensive comments explaining each section's purpose. The structure should be hierarchical with related settings grouped together. Include examples of valid values for each setting, such as `imap.processed_tag: 'AIProcessed'`, `paths.template_file: 'config/note_template.md.j2'`, `openrouter.retry_attempts: 3`, `openrouter.retry_delay_seconds: 5`, `processing.importance_threshold: 8`, `processing.spam_threshold: 5`, etc."
        },
        {
          "id": 2,
          "title": "Implement configuration schema and validation rules",
          "description": "Define a schema that specifies required fields, data types, and validation rules for all configuration parameters",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Create a configuration schema that defines the expected data types, required vs. optional fields, and validation rules for each configuration parameter. Use a schema validation library (like Pydantic, Marshmallow, or jsonschema) to implement the validation logic. Define sensible default values for optional parameters. Ensure the schema aligns exactly with the structure defined in the PDD."
        },
        {
          "id": 3,
          "title": "Create configuration loader module",
          "description": "Implement a module that loads, parses, and validates the YAML configuration file",
          "status": "done",
          "dependencies": [
            2
          ],
          "details": "Create a ConfigLoader class that handles loading the YAML file, parsing it into a Python object, and validating it against the schema. Implement error handling for missing files, syntax errors, and validation failures. The loader should return a validated configuration object that can be used throughout the application. Ensure the loader follows the exact structure specified in the PDD."
        },
        {
          "id": 4,
          "title": "Add environment variable overrides",
          "description": "Implement functionality to override configuration values with environment variables",
          "status": "done",
          "dependencies": [
            3
          ],
          "details": "Extend the configuration loader to check for environment variables that can override values in the config file. Define a naming convention for environment variables (e.g., APP_API_KEY to override api.key). Document this feature in the config file comments. Ensure environment variables are properly type-converted before being applied. CRITICAL: Ensure credentials MUST be loaded from environment variables as a security requirement specified in the PDD."
        },
        {
          "id": 5,
          "title": "Create configuration documentation and example file",
          "description": "Generate comprehensive documentation and an example configuration file with comments",
          "status": "done",
          "dependencies": [
            1,
            2
          ],
          "details": "Create a well-documented example configuration file (config.example.yaml) with detailed comments explaining each setting, its purpose, valid values, and defaults. Include instructions for users on how to create their own config.yaml file. Add a README section explaining the configuration system, environment variable overrides, and validation process. Ensure the documentation references the PDD as the authoritative technical specification."
        },
        {
          "id": 6,
          "title": "Create `settings.py` Configuration Facade",
          "description": "Implement a central facade module that provides getter methods for all configuration values",
          "status": "done",
          "dependencies": [
            3,
            4
          ],
          "details": "Create a settings.py module that acts as a facade for accessing all configuration values. Implement getter methods like `settings.get_openrouter_api_url()`, `settings.get_openrouter_api_key()`, `settings.get_imap_processed_tag()`, etc. for all configuration parameters. Ensure all modules access configuration through this facade, not directly from YAML. Include proper error handling and default values. Document the facade pattern in the module docstring."
        },
        {
          "id": 7,
          "title": "Refactor existing codebase to use `settings.py` facade",
          "description": "Update all code to access configuration through the settings facade rather than directly",
          "status": "done",
          "dependencies": [
            6
          ],
          "details": "Identify all instances of direct configuration access in the codebase (e.g., `config['key']`) and replace them with calls to the settings.py facade methods (e.g., `settings.get_key()`). Ensure all modules import and use the settings module for configuration access. Test thoroughly to verify no direct configuration access remains in the codebase. Document the pattern in the developer guidelines."
        }
      ]
    },
    {
      "id": 2,
      "title": "Implement CLI argument parsing",
      "description": "Create a robust CLI interface with support for the required command flags and subcommands using the click library.",
      "status": "done",
      "dependencies": [
        1
      ],
      "priority": "high",
      "details": "Use click (not argparse) to implement CLI argument parsing as specified in the PDD. Support the following structure: `python main.py process` with flags `--uid <ID>` for targeting specific emails, `--force-reprocess` flag to overwrite existing notes, `--dry-run` flag for testing without side effects, and a separate 'cleanup-flags' subcommand (`python main.py cleanup-flags`). Include help text for each option and implement proper argument validation. For the cleanup-flags command, implement a mandatory confirmation prompt for safety as required by the PDD.",
      "testStrategy": "Test each flag combination to ensure proper parsing. Verify help text is displayed correctly. Test invalid arguments to ensure appropriate error messages. Verify the confirmation prompt works correctly for the cleanup-flags command.",
      "subtasks": [
        {
          "id": 1,
          "title": "Set up basic CLI framework with click",
          "description": "Initialize the CLI framework using click and create the basic command structure",
          "status": "done",
          "dependencies": [],
          "details": "Set up click as the CLI framework as required by the PDD. Create the main command group and set up the basic command structure with subcommands 'process' and 'cleanup-flags'. Include program name, description, and version information. Implement the basic error handling for invalid commands. Ensure the CLI structure follows exactly: `python main.py process` with flags and `python main.py cleanup-flags` as specified in the PDD."
        },
        {
          "id": 2,
          "title": "Implement core flags and options for the process subcommand",
          "description": "Add the primary flags and options to the process subcommand",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Implement the following options for the 'process' subcommand: '--uid <ID>' for targeting specific emails with appropriate type validation, '--force-reprocess' flag to overwrite existing notes, and '--dry-run' flag for testing without side effects. Add detailed help text for each option explaining its purpose and usage. Implement basic argument validation for each option. Ensure the implementation follows the exact structure specified in the PDD."
        },
        {
          "id": 3,
          "title": "Implement the cleanup-flags subcommand",
          "description": "Create the cleanup-flags subcommand with its specific options and behavior",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Add the 'cleanup-flags' subcommand to the CLI parser. Define any specific options needed for this subcommand. Implement the command structure but leave the actual confirmation prompt implementation for the next subtask. Add appropriate help text explaining the purpose and potential impact of this command. Ensure the implementation follows the exact structure specified in the PDD: `python main.py cleanup-flags`."
        },
        {
          "id": 4,
          "title": "Implement confirmation prompt for cleanup-flags",
          "description": "Add a mandatory confirmation prompt for the cleanup-flags command as required by the PDD",
          "status": "done",
          "dependencies": [
            3
          ],
          "details": "Implement a clear and explicit confirmation prompt that warns the user about the effects of the cleanup-flags command. Use a yes/no prompt that requires explicit confirmation (e.g., 'yes' typed out fully) before proceeding. Handle user input validation and provide appropriate feedback. Ensure the command aborts if confirmation is not provided. This is a MANDATORY security requirement from the PDD."
        },
        {
          "id": 5,
          "title": "Integrate argument parsing with main application flow",
          "description": "Connect the CLI parser to the main application logic",
          "status": "done",
          "dependencies": [
            2,
            4
          ],
          "details": "Create a function that parses the arguments using click and returns a structured object with the parsed values. Implement comprehensive error handling for all possible input errors with clear error messages. Add input validation to ensure all required arguments are provided and have valid values. Test the CLI with various combinations of arguments to ensure correct behavior. Document the available commands and options in the help text and in a README section. Ensure all code references the settings.py facade for configuration access."
        }
      ]
    },
    {
      "id": 3,
      "title": "Create IMAP connection and email retrieval module",
      "description": "Develop a module to handle IMAP server connection and email retrieval with support for UID-based targeting.",
      "status": "done",
      "dependencies": [
        1
      ],
      "priority": "high",
      "details": "Implement an IMAP client module (src/imap_client.py) that connects to the server using credentials from the settings.py facade. Create functions to retrieve emails by UID, fetch all unprocessed emails, and handle IMAP flags. Include error handling for connection issues and authentication failures. Implement a function to check if an email has already been processed based on IMAP flags. All configuration access must be through the settings.py facade, not directly from YAML.",
      "testStrategy": "Test connection with valid and invalid credentials. Verify email retrieval by UID works correctly. Test flag checking functionality with processed and unprocessed emails.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement IMAP connection setup with settings facade",
          "description": "Create a module that establishes a connection to an IMAP server using credentials from settings.py facade",
          "status": "done",
          "dependencies": [],
          "details": "Create an ImapClient class in src/imap_client.py that loads server details (host, port, username, password) from the settings.py facade, not directly from config.yaml. Implement a connect() method that establishes a secure connection to the IMAP server using the imaplib library. Include proper error handling for connection failures, authentication issues, and configuration errors. The connection should be reusable and support timeout configurations."
        },
        {
          "id": 2,
          "title": "Develop email retrieval by UID functionality",
          "description": "Create functions to fetch specific emails by their unique identifiers (UIDs)",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Add a get_email_by_uid(uid) method to the ImapClient class that retrieves a specific email using its UID. The method should return the email in a structured format (headers, body parts, attachments). Implement proper error handling for cases where the UID doesn't exist or when fetch operations fail. Include support for different email formats (plain text, HTML, multipart). Use the settings.py facade for any configuration values needed."
        },
        {
          "id": 3,
          "title": "Implement batch email retrieval for unprocessed messages",
          "description": "Create functionality to fetch all unprocessed emails from the IMAP server",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Add a get_unprocessed_emails() method to the ImapClient class that searches for and retrieves all emails that haven't been processed yet (based on absence of specific flags from settings.get_imap_processed_tag()). The method should return a list of email objects with their UIDs. Implement pagination or batching for servers with many emails to prevent memory issues. Include search criteria customization options. Use the settings.py facade for all configuration values."
        },
        {
          "id": 4,
          "title": "Develop IMAP flag management functionality",
          "description": "Create methods to check, set, and clear IMAP flags on email messages",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Add methods to the ImapClient class for flag management: set_flag(uid, flag), clear_flag(uid, flag), and has_flag(uid, flag). These methods should handle standard IMAP flags (\\Seen, \\Answered, \\Flagged, \\Deleted, \\Draft) as well as custom flags. Implement proper error handling for flag operations and support batch operations for multiple UIDs. Use the settings.py facade to access the processed tag name (settings.get_imap_processed_tag())."
        },
        {
          "id": 5,
          "title": "Implement processed email tracking mechanism",
          "description": "Create functionality to track which emails have already been processed",
          "status": "done",
          "dependencies": [
            2,
            4
          ],
          "details": "Implement a is_processed(uid) method that checks if an email has been processed based on IMAP flags (using the processed tag from settings.get_imap_processed_tag(), which should be 'AIProcessed' according to the PDD). Add a mark_as_processed(uid) method that sets the appropriate flag. Create a helper function get_next_unprocessed_email() that returns the next email that needs processing. Include options to customize which flags indicate processed status. All configuration values must be accessed through the settings.py facade."
        }
      ]
    },
    {
      "id": 4,
      "title": "Implement LLM interaction module",
      "description": "Create a module to handle LLM API calls with retry logic and structured JSON response parsing.",
      "status": "done",
      "dependencies": [
        1
      ],
      "priority": "high",
      "details": "Implement an LLM client (src/llm_client.py) that sends prompts requesting structured JSON responses with spam_score and importance_score. Add configurable retry logic for failed API calls. Parse JSON responses and handle malformed responses gracefully. Use the temperature setting from the configuration. Include detailed logging of API interactions for debugging. MUST use settings.get_openrouter_api_url() and settings.get_openrouter_api_key() from settings.py facade. API contract: POST to URL from settings, Bearer token auth, JSON response with {\"spam_score\": <int>, \"importance_score\": <int>}.",
      "testStrategy": "Test successful API calls and response parsing. Verify retry logic works with simulated failures. Test handling of malformed JSON responses. Verify temperature setting is correctly applied.",
      "subtasks": [
        {
          "id": 1,
          "title": "Create basic LLM client structure",
          "description": "Set up the foundation for the LLM client module with settings facade and basic API call functionality",
          "status": "done",
          "dependencies": [],
          "details": "Create a new module src/llm_client.py with a class that handles LLM interactions. Implement configuration loading using the settings.py facade to read API keys (settings.get_openrouter_api_key()), endpoints (settings.get_openrouter_api_url()), and default parameters (including temperature). Define the basic structure for making API calls to the LLM service with proper error handling. Include a method signature for sending prompts that will later be enhanced with retry logic and response parsing. Ensure all configuration access is through the settings facade, not directly from YAML."
        },
        {
          "id": 2,
          "title": "Implement prompt formatting for structured JSON responses",
          "description": "Create functionality to format prompts that specifically request structured JSON responses with required fields",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Develop a prompt formatter that appends instructions to user prompts requesting structured JSON responses. Ensure the formatter explicitly requests spam_score and importance_score fields in the response. Include validation to ensure the prompt maintains the correct format regardless of user input. Create unit tests to verify the formatter correctly structures prompts for JSON responses. The API contract must follow the PDD specification: POST to URL from settings, Bearer token auth, JSON response with {\"spam_score\": <int>, \"importance_score\": <int>}."
        },
        {
          "id": 3,
          "title": "Add configurable retry logic for API calls",
          "description": "Implement robust retry mechanism for handling transient failures in LLM API calls",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Enhance the basic API call functionality with configurable retry logic. Implement exponential backoff strategy with jitter. Make retry attempts (settings.get_openrouter_retry_attempts(), default 3), delays (settings.get_openrouter_retry_delay_seconds(), default 5), and conditions configurable through the settings facade. Handle different types of failures appropriately (network errors, rate limiting, server errors). Add detailed logging for each retry attempt including reason for failure and backoff time."
        },
        {
          "id": 4,
          "title": "Implement JSON response parsing and validation",
          "description": "Create functionality to parse, validate and safely extract data from LLM JSON responses",
          "status": "done",
          "dependencies": [
            1,
            2
          ],
          "details": "Develop a response parser that extracts and validates JSON from LLM responses. Implement schema validation to ensure responses contain required fields (spam_score and importance_score). Handle malformed JSON gracefully with appropriate error messages and fallback values. Create a structured response object that standardizes access to parsed data. Add unit tests with various response scenarios including valid, malformed, and missing field cases. Ensure the parser follows the API contract specified in the PDD."
        },
        {
          "id": 5,
          "title": "Implement comprehensive logging system",
          "description": "Add detailed logging throughout the LLM interaction process for monitoring and debugging",
          "status": "done",
          "dependencies": [
            1,
            3,
            4
          ],
          "details": "Implement a comprehensive logging system that captures all aspects of LLM interactions. Log prompt details (with sensitive information redacted), API call parameters including temperature setting, response data, parsing results, and any errors encountered. Add timing information for performance monitoring. Create different log levels for normal operation vs. debugging. Ensure logs are structured in a way that facilitates analysis and troubleshooting. Integrate the logging with the application's main logging system. Use the settings facade to access log file paths and other logging configuration."
        }
      ]
    },
    {
      "id": 5,
      "title": "Design and implement score-based classification prompt",
      "description": "Create an effective LLM prompt that produces numerical scores for email importance and spam likelihood.",
      "status": "done",
      "dependencies": [
        4
      ],
      "priority": "high",
      "details": "Design a prompt that instructs the LLM to analyze email content and return a JSON object with numerical scores (0-10) for importance_score and spam_score. Include clear scoring criteria in the prompt. Make the prompt configurable via an external file for easy iteration. Ensure the prompt explicitly requests structured JSON output in a consistent format. Reference the PDD for exact score ranges and thresholds (processing.importance_threshold: 8, processing.spam_threshold: 5).",
      "testStrategy": "Test the prompt with various email types (important, spam, neutral) and verify score consistency. Check that scores are within the expected 0-10 range. Verify JSON parsing works reliably with the prompt's output.",
      "subtasks": [
        {
          "id": 1,
          "title": "Define scoring criteria for email importance and spam detection",
          "description": "Create detailed criteria for scoring email importance (0-10) and spam likelihood (0-10)",
          "status": "done",
          "dependencies": [],
          "details": "Research and define specific factors that determine email importance (e.g., sender relationship, urgency indicators, content relevance) and spam likelihood (e.g., suspicious links, keyword patterns, solicitation language). For each factor, specify how it contributes to the numerical score. Document these criteria in a structured format that can be incorporated into the prompt. Include edge cases and examples for each scoring level (0-10) to ensure consistent evaluation. Reference the PDD thresholds (processing.importance_threshold: 8, processing.spam_threshold: 5) to ensure alignment."
        },
        {
          "id": 2,
          "title": "Draft initial LLM prompt template with scoring instructions",
          "description": "Create the core prompt that instructs the LLM how to analyze emails and generate numerical scores",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Write a comprehensive prompt that includes: 1) Clear instructions for the LLM to analyze email content, 2) The scoring criteria defined in subtask 1, 3) Explicit instructions to return a JSON object with importance_score and spam_score fields (both 0-10), 4) Examples of correct scoring for sample emails, and 5) Specific formatting requirements for the JSON output. The prompt should be well-structured with clear sections for instructions, criteria, examples, and output format. Ensure the prompt aligns with the PDD specifications."
        },
        {
          "id": 3,
          "title": "Implement configuration file structure for prompt customization",
          "description": "Design and implement a configuration file format that allows for easy prompt modification",
          "status": "done",
          "dependencies": [
            2
          ],
          "details": "Create a YAML or JSON configuration file structure that allows for customization of the prompt without changing code. The configuration should include: 1) The base prompt template, 2) Scoring criteria parameters that can be adjusted, 3) Example threshold values, and 4) Any other customizable elements. Implement a parser that can read this configuration file and generate the final prompt by substituting variables. Document the configuration options thoroughly. Ensure the configuration can be accessed through the settings.py facade."
        },
        {
          "id": 4,
          "title": "Develop prompt rendering function with configuration integration",
          "description": "Create a function that generates the final prompt by combining the template with configuration values",
          "status": "done",
          "dependencies": [
            2,
            3
          ],
          "details": "Implement a function that: 1) Loads the configuration file through the settings.py facade, 2) Validates the configuration values, 3) Substitutes configuration values into the prompt template, and 4) Returns the fully rendered prompt ready for submission to the LLM. Include error handling for missing or invalid configuration values. The function should be flexible enough to accommodate future changes to the prompt structure without requiring code changes."
        },
        {
          "id": 5,
          "title": "Test and refine the prompt with sample emails",
          "description": "Evaluate the prompt's effectiveness with diverse email samples and refine as needed",
          "status": "done",
          "dependencies": [
            4
          ],
          "details": "Create a test suite with diverse email samples (important/unimportant, spam/legitimate, edge cases). Run these through the LLM using the configured prompt and evaluate: 1) Accuracy of importance and spam scores compared to expected values, 2) Consistency of JSON output format, 3) Handling of edge cases. Document any issues and iteratively refine the prompt and configuration. Create a final report documenting the prompt's performance and any limitations or considerations for future improvements. Ensure scores align with the thresholds specified in the PDD."
        }
      ]
    },
    {
      "id": 6,
      "title": "Implement decision logic with configurable thresholds",
      "description": "Replace the rigid classification system with threshold-based decision logic using numerical scores.",
      "status": "done",
      "dependencies": [
        1,
        5
      ],
      "priority": "high",
      "details": "Create a module that processes the numerical scores from the LLM and applies configurable thresholds to determine email categorization. Implement logic to handle edge cases and score combinations. Use thresholds from the configuration file through the settings.py facade (processing.importance_threshold: 8, processing.spam_threshold: 5). The module should output a classification result that can be used for both note generation and IMAP flag setting.",
      "testStrategy": "Test with various score combinations to verify threshold application. Verify that changing thresholds in the configuration affects classification results appropriately.",
      "subtasks": [
        {
          "id": 1,
          "title": "Create configuration schema for thresholds",
          "description": "Define the structure for threshold configuration in the configuration file",
          "status": "done",
          "dependencies": [],
          "details": "Design and implement a schema for threshold configuration that will be used in the decision logic. This should include threshold values for different classification categories (e.g., importance, urgency, actionability), ranges for scores, and any other parameters needed for the decision logic. Update the configuration file loading mechanism to parse and validate these threshold settings. Ensure the schema aligns with the PDD specifications (processing.importance_threshold: 8, processing.spam_threshold: 5). All threshold values must be accessible through the settings.py facade."
        },
        {
          "id": 2,
          "title": "Develop score processing module",
          "description": "Create a module to process and normalize numerical scores from the LLM",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Implement a module that takes raw numerical scores from the LLM and processes them into a standardized format. This should handle different score ranges, normalize values if needed, and prepare them for threshold comparison. Include validation to ensure scores are within expected ranges and handle cases where scores might be missing or invalid. Use the settings.py facade to access any configuration values needed."
        },
        {
          "id": 3,
          "title": "Implement threshold-based decision logic",
          "description": "Create the core decision logic that applies thresholds to scores",
          "status": "done",
          "dependencies": [
            1,
            2
          ],
          "details": "Develop the main decision logic that compares processed scores against the configured thresholds from the settings.py facade. This should determine email categorization based on the comparison results. Implement conditional logic that can handle various combinations of scores and their relationships to thresholds. The logic should be flexible enough to accommodate different threshold configurations without code changes. Ensure alignment with the PDD specifications."
        },
        {
          "id": 4,
          "title": "Add edge case handling",
          "description": "Implement logic to handle edge cases and special score combinations",
          "status": "done",
          "dependencies": [
            3
          ],
          "details": "Extend the decision logic to handle edge cases such as scores at exactly the threshold value, conflicting classifications, or unusual score combinations. Implement fallback logic for when scores don't clearly fit into defined categories. Add logging for edge cases to help with future refinement of the threshold values. Consider implementing confidence scores for classifications. Use the settings.py facade to access any configuration values needed."
        },
        {
          "id": 5,
          "title": "Create classification result output interface",
          "description": "Develop a standardized output format for classification results",
          "status": "done",
          "dependencies": [
            3,
            4
          ],
          "details": "Design and implement a standardized output format for the classification results that can be consumed by both the note generation module and the IMAP flag setting module. This should include the final classification, confidence levels, the processed scores that led to the decision, and any relevant metadata. Create helper methods to convert the classification result into formats needed by dependent modules. Ensure the output format aligns with the PDD specifications."
        }
      ]
    },
    {
      "id": 7,
      "title": "Integrate templating engine",
      "description": "Set up a templating system for generating Markdown notes based on email content and classification results.",
      "status": "done",
      "dependencies": [
        1
      ],
      "priority": "medium",
      "details": "Integrate Jinja2 or a similar templating engine in src/note_generator.py. Create a template loader that reads template files from a configurable location (paths.template_file: 'config/note_template.md.j2'). Implement a template renderer that combines email data, classification results, and other metadata to generate the final Markdown output. Include proper error handling for template rendering failures. All configuration access must be through the settings.py facade.",
      "testStrategy": "Test template loading with valid and invalid templates. Verify rendering produces expected output with various input combinations. Test error handling with malformed templates.",
      "subtasks": [
        {
          "id": 1,
          "title": "Install and configure templating engine",
          "description": "Set up Jinja2 or a similar templating engine in the project environment",
          "status": "done",
          "dependencies": [],
          "details": "Add Jinja2 to project dependencies. Create a configuration module in src/note_generator.py that defines template-related settings such as template directory paths, file extensions, and caching options. Implement a basic initialization function that creates and configures the templating environment with appropriate settings for the application context. Use the settings.py facade to access the template file path (settings.get_template_file(), which should be 'config/note_template.md.j2' according to the PDD)."
        },
        {
          "id": 2,
          "title": "Implement template loader",
          "description": "Create a template loader that reads template files from a configurable location",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Develop a TemplateLoader class that handles locating and loading template files from the configured directory. Implement methods to list available templates, validate template existence, and load template content. Add support for template inheritance and includes. Ensure the loader handles file system errors gracefully with appropriate exception handling. Use the settings.py facade to access the template file path (settings.get_template_file())."
        },
        {
          "id": 3,
          "title": "Create base templates for email-to-markdown conversion",
          "description": "Design and implement the base Markdown templates for different types of email content",
          "status": "done",
          "dependencies": [
            2
          ],
          "details": "Create a set of base templates for common email-to-markdown conversion scenarios. Include templates for different email classifications (e.g., newsletter, personal, transactional). Design templates with placeholders for email metadata (sender, date, subject), content sections, attachments, and classification results. Structure templates to generate well-formatted Markdown with proper headings, lists, and other formatting elements. Ensure templates align with the PDD specifications."
        },
        {
          "id": 4,
          "title": "Implement template renderer",
          "description": "Develop a renderer that combines email data and classification results with templates",
          "status": "done",
          "dependencies": [
            2,
            3
          ],
          "details": "Create a TemplateRenderer class that takes email data, classification results, and other metadata and renders it using the appropriate template. Implement context preparation functions that transform raw email data into a format suitable for template rendering. Add helper functions for common formatting tasks (date formatting, URL handling, etc.). Include methods to select the most appropriate template based on email classification or content type. Use the settings.py facade for any configuration values needed."
        },
        {
          "id": 5,
          "title": "Add error handling and logging for template rendering",
          "description": "Implement comprehensive error handling for template rendering failures",
          "status": "done",
          "dependencies": [
            4
          ],
          "details": "Enhance the template rendering system with robust error handling. Implement try-except blocks around template rendering operations to catch and handle template syntax errors, missing variables, and rendering failures. Create fallback templates for use when primary templates fail. Add detailed logging of rendering errors with context information to aid debugging. Implement a mechanism to notify users of rendering issues while still providing usable output when possible. Use the settings.py facade to access log file paths and other configuration values."
        }
      ]
    },
    {
      "id": 8,
      "title": "Create default note template",
      "description": "Design a default Markdown template that includes frontmatter for metadata and a structured body for email content.",
      "status": "done",
      "dependencies": [
        7
      ],
      "priority": "medium",
      "details": "Create a default template file that includes YAML frontmatter for storing metadata as specified in PDD Section 3.2, including llm_output section with importance_score, spam_score, model_used and processing_meta section with script_version: \"3.0\", processed_at, status: \"success\" or \"error\". Add dynamic tag addition: add \"important\" tag if score >= threshold. Include a structured body section for email content with placeholders for all relevant email fields (subject, sender, date, body, etc.). Add conditional sections based on classification results. Ensure the template is well-commented for user customization.",
      "testStrategy": "Render the template with various email data to verify output formatting. Check that frontmatter includes all required metadata fields. Verify conditional sections render appropriately based on classification.",
      "subtasks": [
        {
          "id": 1,
          "title": "Define YAML frontmatter structure for email metadata",
          "description": "Create the YAML frontmatter section of the template that will store all email metadata as specified in PDD Section 3.2",
          "status": "done",
          "dependencies": [],
          "details": "Design the frontmatter section at the top of the Markdown template that includes fields as specified in PDD Section 3.2: llm_output section with importance_score, spam_score, model_used and processing_meta section with script_version: \"3.0\", processed_at, status: \"success\" or \"error\". Include dynamic tag addition logic to add \"important\" tag if score >= threshold. Format using proper YAML syntax with clear field names and example values. Add comments explaining each field's purpose and possible values."
        },
        {
          "id": 2,
          "title": "Design structured body section for email content",
          "description": "Create the main body section of the template with placeholders for email content",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Below the frontmatter, create a structured Markdown format for the email body that includes: 1) A header section with rendered versions of key metadata (subject as H1, sender/date as subheading), 2) The main email content section with placeholder text, 3) Formatting for handling attachments list, 4) Proper Markdown syntax for distinguishing quoted replies or forwarded content. Use HTML comments to separate sections for clarity. Ensure the structure aligns with the PDD specifications."
        },
        {
          "id": 3,
          "title": "Implement conditional sections based on classification",
          "description": "Add template sections that appear conditionally based on classification results",
          "status": "done",
          "dependencies": [
            2
          ],
          "details": "Create conditional sections that will render differently based on classification results, including: 1) A warning banner section for high spam_score emails, 2) Visual indicators for importance level, 3) Template variations for different email categories (newsletter, personal, transactional, etc.). Use HTML comments to indicate conditional logic and provide examples of how each condition would render. Implement the dynamic tag addition logic specified in the PDD to add \"important\" tag if score >= threshold."
        },
        {
          "id": 4,
          "title": "Add comprehensive template comments and customization guidance",
          "description": "Include detailed comments throughout the template to guide user customization",
          "status": "done",
          "dependencies": [
            3
          ],
          "details": "Add HTML comments throughout the template that explain: 1) The purpose of each section, 2) How to customize specific elements, 3) Variables/placeholders that will be replaced with actual content, 4) Syntax guidance for advanced formatting options. Ensure comments are clear, helpful for new users, and formatted in a way that won't interfere with the rendered note. Reference the PDD as the authoritative technical specification."
        },
        {
          "id": 5,
          "title": "Create template file with example data and usage instructions",
          "description": "Finalize the template file with example data and add usage documentation",
          "status": "done",
          "dependencies": [
            4
          ],
          "details": "Combine all previous components into a single Markdown template file at the location specified in the PDD (paths.template_file: 'config/note_template.md.j2'). Include a complete example with realistic sample data. Add a 'Template Usage' section at the bottom that explains: 1) How the template will be applied to emails, 2) How to create custom templates, 3) Available variables and their usage, 4) Best practices for template modification. Save the file in the appropriate location in the project structure with proper naming convention as specified in the PDD."
        }
      ]
    },
    {
      "id": 9,
      "title": "Implement local logging of processed emails",
      "description": "Create a local log of processed emails to track processing history and enable debugging.",
      "status": "done",
      "dependencies": [
        1
      ],
      "priority": "medium",
      "details": "Implement TWO separate logging systems as specified in the PDD: 1) Unstructured operational logs → agent.log (from paths.log_file) and 2) Structured analytics → analytics.jsonl (from paths.analytics_file) with fields: uid, timestamp, status, scores. Both must be written for every processed email. Include functions to query the log for specific emails. Ensure log entries are created regardless of processing success or failure.",
      "testStrategy": "Verify log entries are created for successfully processed emails. Check that log entries include all required fields. Test log querying functionality. Verify both logging systems work correctly.",
      "subtasks": [
        {
          "id": 1,
          "title": "Define log data structure and storage format",
          "description": "Design the data structure for email logs and determine the storage format for both logging systems",
          "status": "done",
          "dependencies": [],
          "details": "Create data models for both logging systems as specified in the PDD: 1) Unstructured operational logs (agent.log) and 2) Structured analytics (analytics.jsonl). For the structured analytics, define fields including uid, timestamp, status, and scores. Create utility functions to serialize and deserialize log entries. Include documentation on the chosen formats and rationale. Use the settings.py facade to access log file paths (settings.get_log_file() and settings.get_analytics_file())."
        },
        {
          "id": 2,
          "title": "Implement log file management",
          "description": "Create functions to manage log files including creation, rotation, and configuration of storage location",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Develop a LogManager class that handles file operations for both logging systems. Implement functions to create new log files, append to existing ones, and rotate logs when they reach a certain size. Add configuration options for log file locations (using settings.get_log_file() and settings.get_analytics_file()), maximum file size, and retention policy. Include error handling for file system operations. Ensure thread-safety for concurrent logging operations."
        },
        {
          "id": 3,
          "title": "Create core logging functionality",
          "description": "Implement the main logging functions to record email processing events in both logging systems",
          "status": "done",
          "dependencies": [
            1,
            2
          ],
          "details": "Develop a Logger class with methods to log email processing events to both logging systems. Include functions for logging successful processing, failures, and warnings. Ensure each structured analytics log entry contains all required fields (uid, timestamp, status, scores). Implement different log levels (INFO, ERROR, DEBUG) for the operational logs. Add context information to help with debugging. Make sure logs are created for both successful and failed processing. Both logging systems must be written for every processed email as specified in the PDD."
        },
        {
          "id": 4,
          "title": "Implement log query functionality",
          "description": "Create functions to search and retrieve specific log entries based on various criteria",
          "status": "done",
          "dependencies": [
            1,
            3
          ],
          "details": "Develop query functions to search logs by email UID, subject, date range, or classification result. Implement filtering and sorting capabilities for log retrieval. Create pagination support for large log sets. Add functions to export query results. Ensure query performance is optimized for potentially large log files. Include examples of common query patterns in documentation. Focus primarily on the structured analytics logs for query functionality."
        },
        {
          "id": 5,
          "title": "Integrate logging system with email processor",
          "description": "Connect the logging system with the existing email processing workflow",
          "status": "done",
          "dependencies": [
            3
          ],
          "details": "Modify the email processing code to call appropriate logging functions at key points in the workflow. Add log entries at the start and end of processing, and when classification decisions are made. Ensure errors and exceptions are properly logged with relevant context. Add configuration options to control logging verbosity. Test the integrated system with various email processing scenarios to verify all events are properly logged to both logging systems. Update documentation to explain how to use and interpret the logs. Use the settings.py facade to access all configuration values."
        }
      ]
    },
    {
      "id": 10,
      "title": "Develop error handling for LLM failures",
      "description": "Implement robust error handling for LLM API failures to ensure the system continues functioning.",
      "status": "done",
      "dependencies": [
        4,
        5,
        8
      ],
      "priority": "medium",
      "details": "Create a comprehensive error handling system for LLM API failures. After exhausting retry attempts, generate a note with default error values (spam_score: -1, importance_score: -1) and tag it with #process_error. Status must be set to \"error\" in processing_meta. Include detailed error information in the note. Ensure the system continues processing other emails after an LLM failure.",
      "testStrategy": "Simulate LLM API failures and verify error notes are generated correctly. Check that the error tag is applied and status is set to \"error\". Verify that processing continues with subsequent emails after a failure.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement retry mechanism for LLM API calls",
          "description": "Create a configurable retry system for LLM API calls that handles temporary failures",
          "status": "done",
          "dependencies": [],
          "details": "Develop a retry mechanism with exponential backoff that attempts to reconnect to the LLM API when failures occur. Include configurable parameters for maximum retry attempts, initial delay, and maximum delay between retries. Implement proper logging for each retry attempt with relevant error information. Use the settings.py facade to access retry configuration (settings.get_openrouter_retry_attempts() and settings.get_openrouter_retry_delay_seconds())."
        },
        {
          "id": 2,
          "title": "Create default error response generator",
          "description": "Develop a function that generates standardized error responses when LLM processing fails",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Implement a function that creates a standardized error response object with default values (spam_score: -1, importance_score: -1) when the LLM API fails after exhausting retry attempts, as specified in the PDD. The function should accept the original email data and error information as input parameters and return a properly formatted response object. Ensure the status is set to \"error\" in the processing_meta section as required by the PDD."
        },
        {
          "id": 3,
          "title": "Implement error note creation with detailed error information",
          "description": "Create a system to generate detailed error notes with the #process_error tag",
          "status": "done",
          "dependencies": [
            2
          ],
          "details": "Develop functionality to create comprehensive error notes when LLM processing fails. Each note should include: the #process_error tag, default error values (spam_score: -1, importance_score: -1), original email metadata, error type, error message, timestamp, and any relevant context about the failure. Structure the note in a way that makes debugging easier. Ensure the status is set to \"error\" in the processing_meta section as required by the PDD."
        },
        {
          "id": 4,
          "title": "Develop error isolation and system continuity mechanism",
          "description": "Ensure LLM failures for one email don't affect processing of other emails",
          "status": "done",
          "dependencies": [
            3
          ],
          "details": "Implement error isolation that prevents failures in processing one email from affecting others. Use try-catch blocks or equivalent error boundaries around individual email processing. Ensure the main processing loop continues to the next email after properly handling and logging any errors. Test with simulated failures to verify system resilience. Log all errors to both logging systems (operational logs and structured analytics) as specified in the PDD."
        },
        {
          "id": 5,
          "title": "Create monitoring and alerting for LLM failures",
          "description": "Implement a system to track and alert on LLM failure patterns",
          "status": "done",
          "dependencies": [
            4
          ],
          "details": "Develop monitoring that tracks LLM failure rates and patterns. Implement counters for different error types, track retry success rates, and monitor the frequency of #process_error notes. Create an alerting mechanism that notifies administrators when error rates exceed configurable thresholds. Include a dashboard or reporting feature to visualize error trends over time. Use the settings.py facade to access any configuration values needed for monitoring and alerting."
        }
      ]
    },
    {
      "id": 11,
      "title": "Implement dry-run functionality",
      "description": "Create a non-destructive testing mode that outputs results without writing files or setting flags.",
      "status": "done",
      "dependencies": [
        2,
        3,
        6,
        7
      ],
      "priority": "medium",
      "details": "Implement the --dry-run flag functionality that processes emails and generates output but doesn't write files or set IMAP flags. Output detailed processing information to the console, including classification scores, decision logic results, and the generated note content. Format console output for readability with clear section headers and color coding if possible.",
      "testStrategy": "Run with --dry-run flag and verify no files are written and no IMAP flags are set. Check that console output includes all relevant processing information. Test with various email types to ensure comprehensive output.",
      "subtasks": [
        {
          "id": 1,
          "title": "Add command-line argument parsing for --dry-run flag",
          "description": "Implement the ability to detect and process the --dry-run flag from command-line arguments",
          "status": "done",
          "dependencies": [],
          "details": "Modify the click-based argument parsing logic to recognize the --dry-run flag. Create a global or context variable to track dry-run mode. Update help documentation to describe the new flag. Ensure the dry-run state is accessible throughout the application execution flow. Implement this as part of the 'process' subcommand as specified in the PDD."
        },
        {
          "id": 2,
          "title": "Create conditional logic to bypass file writing operations",
          "description": "Modify file writing operations to be conditional based on dry-run mode",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Identify all locations in the codebase where files are written. Wrap these operations in conditional checks that verify if dry-run mode is active. If in dry-run mode, skip the actual file writing but maintain all the preparation logic. Log what would have been written and where. Use the settings.py facade to access any configuration values needed."
        },
        {
          "id": 3,
          "title": "Implement conditional IMAP flag setting",
          "description": "Modify IMAP flag setting operations to be conditional based on dry-run mode",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Locate all code that sets IMAP flags on emails. Add conditional logic to bypass the actual flag setting when in dry-run mode. Ensure the application still processes the logic of which flags would be set, but doesn't perform the actual IMAP operations to modify the flags. Use the settings.py facade to access any configuration values needed, including the processed tag name (settings.get_imap_processed_tag())."
        },
        {
          "id": 4,
          "title": "Develop enhanced console output formatting",
          "description": "Create structured, readable console output for dry-run results",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Implement a formatting system for console output that includes section headers, indentation, and optional color coding (using a library like chalk for Node.js or colorama for Python). Create helper functions for formatting different types of output (headers, details, success/warning messages). Design a consistent visual hierarchy for the output information. Ensure the formatting is clear and helpful for understanding what would happen in a real run."
        },
        {
          "id": 5,
          "title": "Implement detailed processing information output",
          "description": "Output comprehensive processing details during dry-run mode",
          "status": "done",
          "dependencies": [
            1,
            2,
            3,
            4
          ],
          "details": "Modify the email processing logic to output detailed information when in dry-run mode, including: classification scores with explanation of thresholds, decision logic results showing why certain actions were taken, generated note content in a preview format, file paths where content would have been written, and IMAP flags that would have been set. Use the formatting system from subtask 4 to ensure readability. Include summary statistics at the end of processing. Use the settings.py facade to access any configuration values needed for the output."
        }
      ]
    },
    {
      "id": 12,
      "title": "Implement force-reprocess capability",
      "description": "Add functionality to reprocess already processed emails when explicitly requested.",
      "status": "done",
      "dependencies": [
        2,
        3,
        6
      ],
      "priority": "medium",
      "details": "Implement the --force-reprocess flag functionality that allows reprocessing of emails that have already been processed. This should override the normal flag-based skipping mechanism. Include logic to handle existing output files (overwrite them). Update IMAP flags as needed after reprocessing. Log reprocessing events distinctly in the local log.",
      "testStrategy": "Test reprocessing of already processed emails with and without the flag. Verify files are overwritten when reprocessing. Check that IMAP flags are updated correctly. Verify log entries reflect reprocessing events.",
      "subtasks": [
        {
          "id": 1,
          "title": "Add command-line flag for force-reprocessing",
          "description": "Implement the --force-reprocess command-line flag in the application's click-based argument parser",
          "status": "done",
          "dependencies": [],
          "details": "Modify the click-based argument parser to accept a new boolean flag '--force-reprocess'. Update the help documentation to explain that this flag allows reprocessing of emails that have already been processed. Store this flag value in the application configuration or context object so it can be accessed by the email processing logic. Implement this as part of the 'process' subcommand as specified in the PDD."
        },
        {
          "id": 2,
          "title": "Modify email processing logic to check force-reprocess flag",
          "description": "Update the email processing decision logic to consider the force-reprocess flag when determining whether to process an email",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Locate the code that checks whether an email has already been processed (likely using IMAP flags). Modify this logic to override the normal skip behavior when the --force-reprocess flag is active. The updated logic should process the email even if it has the processed tag (settings.get_imap_processed_tag()) if force-reprocess is enabled. Use the settings.py facade to access any configuration values needed."
        },
        {
          "id": 3,
          "title": "Implement output file handling for reprocessed emails",
          "description": "Add logic to handle existing output files when reprocessing emails",
          "status": "done",
          "dependencies": [
            2
          ],
          "details": "When reprocessing an email that was previously processed, there may be existing output files. Implement logic to detect these files and overwrite them with the new processing results. This may involve checking for file existence before writing and ensuring proper cleanup of old files if the new processing generates different filenames. Use the settings.py facade to access any file path configuration values needed."
        },
        {
          "id": 4,
          "title": "Update IMAP flag handling for reprocessed emails",
          "description": "Ensure IMAP flags are correctly updated after reprocessing an email",
          "status": "done",
          "dependencies": [
            2
          ],
          "details": "After successfully reprocessing an email, the IMAP flags may need to be updated. This could involve temporarily removing the processed tag (settings.get_imap_processed_tag()) before reprocessing and then re-adding it afterward, or implementing a more sophisticated flagging system that tracks reprocessing events. Ensure the flags accurately reflect the email's processing status after reprocessing. Use the settings.py facade to access the processed tag name."
        },
        {
          "id": 5,
          "title": "Enhance logging for reprocessing events",
          "description": "Add distinct logging for email reprocessing events to both logging systems",
          "status": "done",
          "dependencies": [
            2,
            3,
            4
          ],
          "details": "Implement enhanced logging specifically for reprocessing events in both logging systems (operational logs and structured analytics). Log messages should clearly indicate when an email is being reprocessed (as opposed to processed for the first time). Include relevant details such as email ID, subject, and timestamp. These logs should help administrators track and audit reprocessing activities. Consider adding a specific log level or tag for reprocessing events to make them easily filterable. Use the settings.py facade to access log file paths and other configuration values."
        }
      ]
    },
    {
      "id": 13,
      "title": "Create cleanup-flags command",
      "description": "Implement a safeguarded command to remove application-specific flags from the mail server.",
      "status": "pending",
      "dependencies": [
        2,
        3
      ],
      "priority": "low",
      "details": "Implement the 'cleanup-flags' subcommand that removes only application-specific IMAP flags (as defined in the configuration) from emails on the server. Include a MANDATORY confirmation prompt with clear warnings about the operation as required by the PDD (security requirement). Add a dry-run option for this command to show which flags would be removed without actually removing them. Implement detailed logging of flag removal operations.",
      "testStrategy": "Test the command with confirmation and cancellation. Verify only application-specific flags are removed. Check that the dry-run option shows flags without removing them. Verify logging of flag removal operations.",
      "subtasks": [
        {
          "id": 1,
          "title": "Define configuration structure for application-specific IMAP flags",
          "description": "Create a configuration schema to define which IMAP flags are considered application-specific and should be managed by the cleanup command",
          "status": "pending",
          "dependencies": [],
          "details": "Implement a configuration section in the application's config file that allows users to define which IMAP flags are considered application-specific. The configuration should include: 1) A list of flag patterns to match (e.g., 'MyApp/*'), 2) Optional exclusion patterns, 3) Documentation on the format and impact of these settings. Ensure the configuration is validated when loaded and provide helpful error messages for invalid configurations. Use the settings.py facade to access these configuration values."
        },
        {
          "id": 2,
          "title": "Implement flag scanning functionality",
          "description": "Create a module to scan and identify application-specific flags on emails based on the configuration",
          "status": "pending",
          "dependencies": [
            1
          ],
          "details": "Develop a function that connects to the IMAP server, scans emails in specified folders, and identifies flags matching the patterns defined in the configuration. The function should: 1) Accept connection parameters and folder specifications, 2) Return a structured report of emails and their matching flags, 3) Include error handling for connection issues, 4) Be optimized for performance with large mailboxes by using appropriate IMAP commands and batching. Use the settings.py facade to access any configuration values needed."
        },
        {
          "id": 3,
          "title": "Implement dry-run functionality",
          "description": "Create a command option and supporting code to preview flag removal operations without making changes",
          "status": "pending",
          "dependencies": [
            2
          ],
          "details": "Implement a '--dry-run' flag for the command that shows which flags would be removed without actually removing them. The output should: 1) List each email that would be affected (showing identifiers like UID and subject), 2) Show which flags would be removed from each email, 3) Provide summary statistics (total emails affected, total flags to be removed), 4) Format the output in a clear, readable way. This functionality should reuse the scanning module from subtask 2 but skip the actual modification steps."
        },
        {
          "id": 4,
          "title": "Implement flag removal functionality with confirmation prompt",
          "description": "Create the core functionality to remove identified flags with a mandatory confirmation step as required by the PDD",
          "status": "pending",
          "dependencies": [
            2
          ],
          "details": "Implement the actual flag removal functionality with a MANDATORY confirmation prompt as required by the PDD (security requirement). The implementation should: 1) Present a clear warning about the operation's impact, 2) Show a summary of what will be modified, 3) Require explicit confirmation (e.g., typing 'yes' or similar), 4) Abort if confirmation is not provided, 5) Include safeguards to prevent accidental removal of system or critical flags, 6) Implement the actual IMAP commands to remove the flags when confirmed. Ensure proper error handling and transaction safety where possible."
        },
        {
          "id": 5,
          "title": "Implement detailed logging and integrate command into CLI",
          "description": "Add comprehensive logging of operations and integrate the new subcommand into the application's CLI structure",
          "status": "pending",
          "dependencies": [
            3,
            4
          ],
          "details": "Complete the command by adding detailed logging and CLI integration. The implementation should: 1) Log all operations with appropriate detail levels (info for summaries, debug for individual operations), 2) Include timestamps, affected email IDs, and specific flags in logs, 3) Log both successful and failed operations, 4) Register the 'cleanup-flags' subcommand in the application's command structure with proper help text and option definitions, 5) Ensure the command follows the application's existing CLI patterns and conventions, 6) Add documentation for the new command in the application's help system and user documentation. Use the settings.py facade to access log file paths and other configuration values."
        }
      ]
    },
    {
      "id": 14,
      "title": "Integrate all components into main processing flow",
      "description": "Combine all modules into a cohesive email processing pipeline with appropriate control flow.",
      "status": "pending",
      "dependencies": [
        3,
        4,
        6,
        7,
        9,
        10,
        11,
        12
      ],
      "priority": "high",
      "details": "Integrate all components into a main processing flow that handles: email retrieval (all or by UID), LLM classification, decision logic application, note generation, file writing, and IMAP flag setting. Implement appropriate control flow based on CLI arguments (--dry-run, --force-reprocess, --uid). Include comprehensive logging throughout the process. Ensure proper error handling at each step to prevent crashes. Create src/orchestrator.py for high-level business logic orchestration. Add performance requirement: Local operations < 1s, no memory leaks during batch processing. Update to use click (not argparse) for CLI parsing. Reference settings.py facade throughout.",
      "testStrategy": "Test the complete processing flow with various CLI argument combinations. Verify correct behavior for single email processing and batch processing. Check error handling with simulated failures at different stages. Verify performance meets requirements.",
      "subtasks": [
        {
          "id": 1,
          "title": "Create core pipeline architecture and CLI argument handling",
          "description": "Establish the main program structure with click-based CLI argument parsing and basic control flow",
          "status": "done",
          "dependencies": [],
          "details": "Implement the main entry point that parses CLI arguments (--dry-run, --force-reprocess, --uid) using click as specified in the PDD. Create a Pipeline class in src/orchestrator.py that will orchestrate the entire email processing flow. Set up the basic program structure with configuration loading through the settings.py facade, logging initialization, and error handling framework. Define the high-level pipeline steps as methods that will be implemented in subsequent tasks. Ensure the CLI structure follows exactly: `python main.py process` with flags as specified in the PDD."
        },
        {
          "id": 2,
          "title": "Implement email retrieval and selection logic",
          "description": "Add the ability to retrieve emails from IMAP and select which ones to process based on CLI arguments",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Integrate the email retrieval module (src/imap_client.py) into the pipeline. Implement logic to either retrieve all emails or specific emails by UID based on CLI arguments. Add filtering to exclude already processed emails unless --force-reprocess is specified. Include appropriate logging for the retrieval process and error handling for IMAP connection issues. Return a collection of email objects that will be passed to the next pipeline stage. Use the settings.py facade to access all configuration values, including the processed tag name (settings.get_imap_processed_tag())."
        },
        {
          "id": 3,
          "title": "Integrate LLM classification and decision logic",
          "description": "Connect the LLM classification module and implement the decision tree for email processing",
          "status": "done",
          "dependencies": [
            2
          ],
          "details": "For each email retrieved in the previous step, call the LLM classification module (src/llm_client.py) to categorize the email. Implement the decision logic that determines what actions to take based on the classification results. Include conditional logic that respects the --dry-run flag to prevent actual modifications when in dry run mode. Add comprehensive logging of classification results and decisions to both logging systems. Implement error handling for LLM API failures with appropriate fallback strategies. Use the settings.py facade to access all configuration values, including thresholds (settings.get_importance_threshold() and settings.get_spam_threshold())."
        },
        {
          "id": 4,
          "title": "Add note generation and file writing capabilities",
          "description": "Integrate note generation for classified emails and implement file writing functionality",
          "status": "done",
          "dependencies": [
            3
          ],
          "details": "For emails that require notes based on the decision logic, call the note generation module (src/note_generator.py). Implement the file writing functionality to save generated notes to the appropriate location with proper naming conventions. Create directory structures if they don't exist. Add logging for file operations and implement error handling for file system issues. Ensure the --dry-run flag prevents actual file writing while still logging what would have been written. Use the settings.py facade to access all configuration values, including file paths."
        },
        {
          "id": 5,
          "title": "Implement IMAP flag setting and finalize pipeline execution flow",
          "description": "Add the ability to mark emails as processed in IMAP and complete the end-to-end pipeline",
          "status": "pending",
          "dependencies": [
            4
          ],
          "details": "Integrate the IMAP flag setting module to mark emails as processed after successful handling. Respect the --dry-run flag to prevent actual flag modifications in dry run mode. Implement the final pipeline execution flow that chains all components together with proper error propagation. Add summary logging at the end of processing with statistics (emails processed, errors encountered, etc.). Implement cleanup operations for resources like IMAP connections. Test the entire pipeline with various combinations of CLI arguments to ensure proper functioning. Ensure performance meets requirements: Local operations < 1s, no memory leaks during batch processing. Use the settings.py facade to access all configuration values."
        },
        {
          "id": 6,
          "title": "Create src/orchestrator.py for high-level business logic orchestration",
          "description": "Implement a central orchestration module to coordinate all components of the system",
          "status": "pending",
          "dependencies": [
            5
          ],
          "details": "Create src/orchestrator.py to serve as the central coordination point for the application's business logic. This module should: 1) Define high-level workflow functions that coordinate the interactions between other modules, 2) Implement the main processing pipeline that handles the end-to-end email processing flow, 3) Manage state and context throughout the processing lifecycle, 4) Handle error propagation and recovery strategies, 5) Implement performance optimizations to meet the requirement of local operations < 1s and no memory leaks during batch processing. Use the settings.py facade to access all configuration values. Document the orchestrator's architecture and responsibilities clearly."
        }
      ]
    },
    {
      "id": 15,
      "title": "Implement backfill functionality for historical emails",
      "description": "Create a mechanism to process all historical emails with the new classification system.",
      "status": "pending",
      "dependencies": [
        14
      ],
      "priority": "low",
      "details": "Implement a backfill function that processes all emails in the target mailbox, regardless of their current flag status. Include options to limit the backfill by date range or folder. Add a progress indicator for long-running backfill operations. Implement throttling to prevent API rate limiting issues. Include detailed logging of the backfill process with summary statistics.",
      "testStrategy": "Test backfill on a small subset of emails before full execution. Verify all emails are processed correctly. Check that progress indication works for long-running operations. Verify throttling prevents API rate limiting issues.",
      "subtasks": [
        {
          "id": 1,
          "title": "Design backfill function core with date range and folder filtering",
          "description": "Create the core backfill function that can process historical emails with configurable filters",
          "status": "pending",
          "dependencies": [],
          "details": "Implement a function that accepts parameters for date range (startDate, endDate) and folder path. The function should query the email API to retrieve all emails matching these criteria. Include parameter validation and default values (all time, all folders). Structure the function to support batch processing of emails and ensure it correctly applies the new classification system to each email. Return a data structure that can be used for progress tracking and logging. Use the settings.py facade to access any configuration values needed."
        },
        {
          "id": 2,
          "title": "Implement progress tracking mechanism",
          "description": "Create a system to track and display progress during backfill operations",
          "status": "pending",
          "dependencies": [
            1
          ],
          "details": "Build a progress tracking class that maintains counts of total emails to process, emails processed, success/failure counts, and percentage complete. Implement methods to update this progress as emails are processed. Create both console output for command-line usage and a UI component for displaying progress in the application interface. The progress tracker should support both determinate (when total count is known) and indeterminate modes (when total count is unknown). Use the settings.py facade to access any configuration values needed."
        },
        {
          "id": 3,
          "title": "Add throttling mechanism to prevent API rate limiting",
          "description": "Implement controls to limit the rate of API calls during backfill operations",
          "status": "pending",
          "dependencies": [
            1
          ],
          "details": "Create a throttling mechanism that limits API calls to a configurable rate (e.g., X calls per minute). Implement using either a token bucket algorithm or simple time-based throttling. Add retry logic with exponential backoff for handling rate limit errors from the API. Make the throttling parameters configurable based on the API's documented limits. Ensure the throttling mechanism properly handles batches of requests and maintains a consistent processing rate. Use the settings.py facade to access throttling configuration values (settings.get_openrouter_retry_attempts() and settings.get_openrouter_retry_delay_seconds())."
        },
        {
          "id": 4,
          "title": "Implement comprehensive logging system",
          "description": "Create detailed logging for the backfill process with summary statistics",
          "status": "pending",
          "dependencies": [
            1,
            2
          ],
          "details": "Implement a logging system that records: start/end times, configuration parameters used, progress updates at regular intervals, any errors encountered with full stack traces, and summary statistics upon completion. Create different log levels (debug, info, warning, error) and ensure appropriate information is logged at each level. Generate a summary report at the end of the backfill showing total emails processed, success rate, error counts by type, and processing time. Store logs in a structured format that can be easily analyzed. Use the settings.py facade to access log file paths and other configuration values."
        },
        {
          "id": 5,
          "title": "Create user interface for backfill configuration and execution",
          "description": "Develop a UI to allow users to configure and initiate backfill operations",
          "status": "pending",
          "dependencies": [
            1,
            2,
            3,
            4
          ],
          "details": "Build a user interface that allows configuration of all backfill parameters: date range selection with calendar controls, folder selection with a folder browser, throttling settings, and logging options. Include validation to prevent invalid configurations. Display the progress indicator during operation and show the summary report upon completion. Add the ability to cancel an in-progress backfill operation. Ensure the UI remains responsive during long-running backfill operations by using background processing. Use the settings.py facade to access any configuration values needed for the UI."
        }
      ]
    }
  ],
  "metadata": {
    "projectName": "Email Agent V3 Foundational Upgrade",
    "totalTasks": 15,
    "sourceFile": "c:\\Users\\Marc Bielert\\Github\\email-agent\\prd.md",
    "generatedAt": "2023-11-12"
  }
}