# Task ID: 7
# Title: Implement LLM integration for email summarization
# Status: pending
# Dependencies: 6
# Priority: medium
# Description: Create the functionality to call an LLM API for generating email summaries
# Details:
Implement the LLM API call functionality using the loaded prompt and email content. Structure the prompt to generate concise, informative summaries focusing on key points and action items. Include error handling for API failures, rate limiting, and malformed responses. The system should log errors but continue processing if summarization fails.

# Test Strategy:
Test with various email contents including short messages, long threads, and emails with different structures. Verify the summaries are accurate and helpful. Test error handling by simulating API failures.

# Subtasks:
## 1. Create prompt template for email summarization [pending]
### Dependencies: None
### Description: Design and implement a structured prompt template that combines the loaded prompt with email content to generate concise summaries focusing on key points and action items.
### Details:
Load the existing prompt configuration. Create a prompt formatter using f-strings or a templating library (e.g., Jinja2) that injects email fields: subject, sender, body, date. Structure the prompt to explicitly request: 1) 2-3 sentence summary of main content, 2) bullet-point list of action items, 3) priority level (low/medium/high). Test template rendering with sample email data to ensure proper formatting and token limits.

## 2. Implement core LLM API integration [pending]
### Dependencies: 7.1
### Description: Build the LLM API client and core summarization function that calls the external LLM API using the formatted prompt from subtask 1.
### Details:
Use requests library or LLM client SDK (e.g., openai-python, litellm for multi-provider support). Implement async function `summarize_email(email_data)` that: 1) formats prompt using template from subtask 1, 2) makes POST request to LLM endpoint with proper headers (Authorization, Content-Type), 3) sends JSON payload with model name, prompt, temperature=0.3, max_tokens=300. Return raw API response. Include timeout (30s) and basic request validation.

## 3. Add comprehensive error handling and fallbacks [pending]
### Dependencies: 7.2
### Description: Implement robust error handling for API failures, rate limiting, malformed responses, and network issues while ensuring the system continues processing.
### Details:
Wrap API call in try-except blocks handling: HTTPError (4xx/5xx), ConnectionError, Timeout, JSONDecodeError. Implement exponential backoff retry (3 attempts, 1s/2s/4s delays) for 429 rate limits and 5xx errors. For failures, return fallback summary: 'Summary unavailable - please read original email'. Validate response structure (check for 'choices[0].message.content'). Log all errors with structured logging (email_id, error_type, response_status).

## 4. Implement response parsing and validation [pending]
### Dependencies: 7.2, 7.3
### Description: Parse LLM responses into structured summary objects and validate output quality before returning to the calling system.
### Details:
Create `parse_summary_response(raw_response)` function that: 1) extracts content from standard LLM response format, 2) strips markdown/whitespace, 3) validates minimum length (>20 chars) and maximum length (<500 chars), 4) checks for key phrases ('action items', 'summary') using regex, 5) returns structured dict: {'summary': str, 'action_items': list[str], 'priority': str, 'success': bool}. Default to empty values on parsing failure.

## 5. Add logging, monitoring, and integration wrapper [pending]
### Dependencies: 7.1, 7.2, 7.3, 7.4
### Description: Implement production-ready logging, metrics, and a complete wrapper function that integrates all previous subtasks with proper error boundaries.
### Details:
Create main `generate_email_summary(email_data)` function that orchestrates subtasks 1-4. Add structured logging at each step (INFO: prompt formatted, API called; ERROR: failures with email_id). Track metrics: api_latency, success_rate, token_usage, error_type. Implement circuit breaker pattern (pause after 5 consecutive failures). Ensure function signature matches existing system expectations and gracefully handles all edge cases while maintaining processing flow.

